# Deep_learning--Spam_Detector--AT-T

Fictive project completed as part of my Data Scientist Training with jedha Bootcamp (Paris)

## Project ğŸš§

One of the main pain point that AT&T users are facing is constant exposure to SPAM messages.

AT&T has been able to manually flag spam messages for a time, but they are looking for an automated way of detecting spams to protect their users.

## Goals ğŸ¯
The goal for this project is to build a spam detector, that can automatically flag spams as they come based solely on the sms' content.

## Scope of this project ğŸ–¼ï¸

Dataset used for this project : [Dowload the Dataset](https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com/Deep+Learning/project/spam.csv)

## ğŸ“ Project Structure
```
Deep_learning--Spam_Detector--AT-T/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ AT&T_PART1-Preprocessing.ipynb
â”‚ â”œâ”€â”€ AT&T_data_preprocessed.csv
â”‚ â”œâ”€â”€ AT&T_PART2_Baseline-model.ipynb
â”‚ â”œâ”€â”€ AT&T_PART3_DistilBERTwithTensorflow.ipynb
â”‚ â”œâ”€â”€ AT&T_PART4_DistilBERT+LRwithPyTorch.ipynb
â”‚ â””â”€â”€ AT&T_Spam_Detector.ipynb
â”œâ”€â”€ Models_trained/
â”‚ â”œâ”€â”€ DistilBERT_ft/
â”‚ â”œâ”€â”€ DistilBERT+lr/
â”‚ â”œâ”€â”€ Baseline_model.joblib
â”‚ â””â”€â”€ tokenizer_baseline_model.json
â”œâ”€â”€ Evaluations/
â”‚ â”œâ”€â”€ DistilBERT_lr/
â”‚ â”œâ”€â”€ baseline_model_metrics.json
â”‚ â”œâ”€â”€ DistilBERT_ft_metrics.json
â”‚ â””â”€â”€ DistilBERT_ft_threshold_metrics.json
â””â”€â”€ README.md    
```
## Models tested ğŸ“¬

 1. A simple deep learning model with good results :     
  **Model architecture :**     
  ![Sans titre](https://github.com/user-attachments/assets/bb334c9d-30a9-4409-9e86-0e93c6c81ac8)     
  **Model metrics :**     
  ![Sans titre](https://github.com/user-attachments/assets/57a8ab20-bf4e-47c7-b4d0-bbc205258c9b)  
  **Model confusion matrice :**     
  ![Sans titre](https://github.com/user-attachments/assets/be95d6a5-41f0-40c8-ab6f-774280a94755)
![Sans titre](https://github.com/user-attachments/assets/14a0ccc5-2f33-4d81-a262-241767a50382)
```
Classification_report - Training set
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      3161
           1       1.00      0.98      0.99       457

    accuracy                           1.00      3618
   macro avg       1.00      0.99      0.99      3618
weighted avg       1.00      1.00      1.00      3618

Classification_report - Validation set
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      1355
           1       0.98      0.86      0.92       196

    accuracy                           0.98      1551
   macro avg       0.98      0.93      0.95      1551
weighted avg       0.98      0.98      0.98      1551
```     


 2. A DistrilBERT pretrained model finetuned with tensorflow with low efficiency results:
  
